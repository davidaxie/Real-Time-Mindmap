<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AI-Powered Realtime Mindmap</title>
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap"
      rel="stylesheet"
    />
    <style>
      :root {
        color-scheme: light;
        font-family: "Inter", system-ui, -apple-system, BlinkMacSystemFont,
          sans-serif;
        background: #f7f4ef;
        color: #1f2933;
      }
      body {
        margin: 0;
        min-height: 100vh;
        display: flex;
        flex-direction: column;
        background: radial-gradient(
            circle at top left,
            rgba(226, 232, 240, 0.6),
            transparent 55%
          ),
          radial-gradient(
            circle at bottom right,
            rgba(244, 219, 216, 0.55),
            transparent 50%
          ),
          #f7f4ef;
      }
      header {
        padding: 2.5rem 1.5rem 1.5rem;
        text-align: center;
        color: #111827;
      }
      header h1 {
        margin: 0;
        font-size: clamp(2rem, 4vw, 2.8rem);
        font-weight: 600;
        letter-spacing: -0.03em;
      }
      header p {
        margin: 0.75rem auto 0;
        max-width: 760px;
        line-height: 1.65;
        color: rgba(55, 65, 81, 0.75);
      }
      main {
        flex: 1;
        display: grid;
        gap: 1.5rem;
        grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
        padding: 0 1.5rem 2.5rem;
      }
      section {
        backdrop-filter: blur(14px);
        background: rgba(255, 255, 255, 0.82);
        border: 1px solid rgba(209, 213, 219, 0.7);
        border-radius: 18px;
        box-shadow: 0 18px 40px rgba(15, 23, 42, 0.08);
        overflow: hidden;
        display: flex;
        flex-direction: column;
      }
      section h2 {
        margin: 0;
        padding: 1.2rem 1.5rem 0.75rem;
        font-size: 0.95rem;
        font-weight: 600;
        text-transform: uppercase;
        letter-spacing: 0.12em;
        color: rgba(107, 114, 128, 0.9);
      }
      .section-body {
        padding: 0 1.5rem 1.5rem;
        display: flex;
        flex-direction: column;
        gap: 1rem;
        flex: 1;
      }
      #controls {
        display: flex;
        flex-wrap: wrap;
        gap: 0.75rem;
      }
      button {
        border: 1px solid rgba(99, 102, 241, 0.22);
        border-radius: 999px;
        padding: 0.65rem 1.2rem;
        font-weight: 600;
        font-size: 0.95rem;
        cursor: pointer;
        color: #312e81;
        background: linear-gradient(135deg, #ede9fe, #e0e7ff);
        transition: transform 0.2s ease, box-shadow 0.2s ease,
          border-color 0.2s ease;
        box-shadow: 0 8px 18px rgba(129, 140, 248, 0.2);
      }
      button.secondary {
        background: #ffffff;
        color: #1f2933;
        border-color: rgba(209, 213, 219, 0.8);
        box-shadow: none;
      }
      button.danger {
        background: linear-gradient(135deg, #fee2e2, #fecaca);
        color: #b91c1c;
        border-color: rgba(248, 113, 113, 0.4);
        box-shadow: 0 8px 18px rgba(248, 113, 113, 0.2);
      }
      button:disabled {
        cursor: not-allowed;
        opacity: 0.6;
        box-shadow: none;
      }
      button:not(:disabled):hover {
        transform: translateY(-1px);
        border-color: rgba(99, 102, 241, 0.4);
      }
      .status-line {
        display: flex;
        flex-wrap: wrap;
        gap: 0.5rem;
        align-items: center;
        font-size: 0.9rem;
        color: rgba(55, 65, 81, 0.75);
      }
      .status-indicator {
        width: 10px;
        height: 10px;
        border-radius: 50%;
        background: #f97316;
        box-shadow: 0 0 0 0 rgba(249, 115, 22, 0.3);
        animation: pulse 2s infinite;
      }
      .status-indicator.active {
        background: #22c55e;
        box-shadow: 0 0 0 8px rgba(34, 197, 94, 0);
      }
      @keyframes pulse {
        0% {
          box-shadow: 0 0 0 0 rgba(34, 197, 94, 0.45);
        }
        70% {
          box-shadow: 0 0 0 10px rgba(34, 197, 94, 0);
        }
        100% {
          box-shadow: 0 0 0 0 rgba(34, 197, 94, 0);
        }
      }
      .control-grid {
        display: grid;
        gap: 0.75rem 1.25rem;
        grid-template-columns: repeat(auto-fit, minmax(180px, 1fr));
      }
      .control-grid label {
        font-size: 0.78rem;
        text-transform: uppercase;
        letter-spacing: 0.08em;
        color: rgba(107, 114, 128, 0.85);
      }
      .control-grid select,
      .control-grid input[type="text"],
      .control-grid input[type="range"] {
        width: 100%;
        padding: 0.55rem 0.7rem;
        border-radius: 12px;
        border: 1px solid rgba(209, 213, 219, 0.9);
        background: #fdfdfb;
        color: #1f2933;
        font-family: inherit;
      }
      .control-grid .range-value {
        font-size: 0.82rem;
        color: rgba(55, 65, 81, 0.7);
      }
      .hint {
        font-size: 0.82rem;
        color: rgba(75, 85, 99, 0.75);
        line-height: 1.5;
      }
      #live-transcript,
      #translation-live {
        min-height: 80px;
        padding: 1rem;
        border-radius: 12px;
        background: rgba(249, 250, 251, 0.9);
        border: 1px solid rgba(209, 213, 219, 0.7);
        line-height: 1.7;
        color: #1f2937;
      }
      #transcript-log,
      #translation-history {
        flex: 1;
        overflow-y: auto;
        max-height: 320px;
        padding-right: 0.75rem;
      }
      .segment,
      .translation-item {
        padding: 0.85rem 1rem;
        margin-bottom: 0.75rem;
        background: rgba(255, 255, 255, 0.95);
        border-radius: 14px;
        border: 1px solid rgba(226, 232, 240, 0.9);
        box-shadow: 0 4px 12px rgba(15, 23, 42, 0.04);
      }
      .segment time,
      .translation-item time {
        font-size: 0.75rem;
        text-transform: uppercase;
        letter-spacing: 0.08em;
        color: rgba(107, 114, 128, 0.7);
      }
      .segment p,
      .translation-item p {
        margin: 0.45rem 0 0;
        line-height: 1.6;
        color: #1f2937;
      }
      .translation-item .meta {
        display: flex;
        gap: 0.5rem;
        flex-wrap: wrap;
        font-size: 0.75rem;
        color: rgba(107, 114, 128, 0.7);
        margin-top: 0.4rem;
      }
      #mindmap {
        width: 100%;
        flex: 1;
        min-height: 520px;
        border-top: 1px solid rgba(209, 213, 219, 0.6);
        background: rgba(241, 245, 249, 0.85);
      }

      #mindmap > div {
        width: 100%;
        height: 100%;
      }
      #details {
        flex: 1;
        overflow-y: auto;
        max-height: 260px;
      }
      .detail-item {
        padding: 0.8rem 0;
        border-bottom: 1px solid rgba(226, 232, 240, 0.9);
      }
      .detail-item:last-child {
        border-bottom: none;
      }
      textarea {
        width: 100%;
        min-height: 90px;
        border-radius: 12px;
        border: 1px solid rgba(209, 213, 219, 0.9);
        background: #ffffff;
        color: #1f2933;
        padding: 0.8rem;
        font-family: inherit;
        resize: vertical;
      }
      .metric-pill {
        display: inline-flex;
        align-items: center;
        gap: 0.35rem;
        padding: 0.3rem 0.65rem;
        border-radius: 999px;
        background: rgba(226, 232, 240, 0.8);
        color: #1f2937;
        font-size: 0.75rem;
        text-transform: uppercase;
        letter-spacing: 0.08em;
      }
      .metric-pill.danger {
        background: rgba(254, 226, 226, 0.85);
        color: #b91c1c;
      }
      .metric-pill.success {
        background: rgba(220, 252, 231, 0.85);
        color: #15803d;
      }
      .status-stack {
        display: flex;
        flex-direction: column;
        gap: 0.35rem;
      }
      .status-stack small {
        color: rgba(75, 85, 99, 0.7);
      }
      .api-key-input {
        font-size: 0.85rem !important;
        font-family: monospace;
      }
      @media (max-width: 768px) {
        header {
          padding-top: 2rem;
        }
        main {
          padding-bottom: 1.5rem;
        }
        #cy {
          min-height: 420px;
        }
      }
    </style>
    <script src="./node_modules/mind-elixir/dist/MindElixir.iife.js"></script>
    <link
      rel="stylesheet"
      href="./node_modules/mind-elixir/dist/MindElixir.css"
    />
  </head>
  <body>
    <header>
      <h1>AI-Powered Realtime Mindmap</h1>
      <p>
        Capture discussions, lectures, and meetings as they happen. Speech is
        transcribed live, analyzed by AI to extract key concepts and themes, and
        visualised as an evolving mindmap so you can spot themes, action items,
        and emerging ideas instantly.
      </p>
    </header>
    <main>
      <section>
        <h2>Configuration</h2>
        <div class="section-body">
          <div class="control-grid">
            <div>
              <label for="model-select">Groq Model</label>
              <select id="model-select">
                <option value="llama-3.1-8b-instant">
                  Llama 3.1 8B Instant
                </option>
                <option value="llama-3.1-70b-versatile">
                  Llama 3.1 70B Versatile
                </option>
                <option value="mixtral-8x7b-32768">Mixtral 8x7B</option>
                <option value="gemma2-9b-it">Gemma 2 9B</option>
              </select>
            </div>
          </div>
          <p class="hint">
            The API key is securely stored on the backend. Select your preferred
            AI model.
          </p>
        </div>
      </section>

      <section>
        <h2>Capture Controls</h2>
        <div class="section-body">
          <div id="controls">
            <button id="start-btn">Start Listening</button>
            <button id="pause-btn" class="secondary" disabled>Pause</button>
            <button id="stop-btn" class="danger" disabled>
              Stop &amp; Reset
            </button>
            <button id="export-btn" class="secondary" disabled>
              Export JSON
            </button>
            <button id="load-btn" class="secondary">Load JSON</button>
            <input
              type="file"
              id="file-input"
              accept=".json"
              style="display: none"
            />
          </div>
          <div class="status-line">
            <span id="status-indicator" class="status-indicator"></span>
            <span id="status-text">Idle • microphone permissions required</span>
          </div>
          <div class="control-grid">
            <div>
              <label for="source-lang">Source language (ASR)</label>
              <select id="source-lang"></select>
            </div>
            <div>
              <label for="note-input">Add manual note</label>
              <textarea
                id="note-input"
                placeholder="Type a note or idea and press ⌘/Ctrl + Enter"
              ></textarea>
            </div>
          </div>
          <p class="hint">
            The recogniser keeps a rolling buffer. Pause when silence exceeds a
            few seconds to help with processing. The mindmap uses a heap layout:
            nodes with highest weight stay in the center, others branch out by
            weight.
          </p>
        </div>
      </section>

      <section>
        <h2>Live Transcript</h2>
        <div class="section-body">
          <div id="live-transcript">Waiting for speech…</div>
          <div id="transcript-log"></div>
        </div>
      </section>

      <section>
        <h2>AI Analysis</h2>
        <div class="section-body">
          <div class="status-stack" id="ai-status">
            <div class="metric-pill">Ready</div>
            <small
              >AI will analyze your speech to extract key concepts and
              themes.</small
            >
          </div>
          <div
            id="ai-output"
            style="
              min-height: 80px;
              padding: 1rem;
              border-radius: 12px;
              background: rgba(249, 250, 251, 0.9);
              border: 1px solid rgba(209, 213, 219, 0.7);
              line-height: 1.7;
              color: #1f2937;
            "
          >
            AI insights will appear here...
          </div>
        </div>
      </section>

      <section style="grid-column: 1 / -1; min-height: 640px">
        <h2>Mindmap</h2>
        <div id="mindmap"></div>
      </section>

      <section>
        <h2>Focus Panel</h2>
        <div class="section-body" id="details">
          <p>
            Select a node in the mindmap to see the most recent notes and quotes
            linked to it.
          </p>
        </div>
      </section>
    </main>

    <script>
      const SpeechRecognition =
        window.SpeechRecognition || window.webkitSpeechRecognition;

      // STOPWORDS removed - AI handles intelligent filtering

      const LANGUAGE_OPTIONS = [
        { code: "auto", label: "Auto detect" },
        { code: "en-US", label: "English (United States)" },
        { code: "en-GB", label: "English (United Kingdom)" },
        { code: "es-ES", label: "Spanish" },
        { code: "fr-FR", label: "French" },
        { code: "de-DE", label: "German" },
        { code: "pt-BR", label: "Portuguese (Brazil)" },
        { code: "it-IT", label: "Italian" },
        { code: "hi-IN", label: "Hindi" },
        { code: "ja-JP", label: "Japanese" },
        { code: "zh-CN", label: "Chinese (Mandarin)" },
      ];

      const graph = {
        nodes: new Map(),
        edges: new Map(),
      };

      // Global API call queue variables
      let apiCallQueue = [];
      let isProcessingQueue = false;

      // Global API call queue to serialize requests
      async function queueAPICall(apiFunction) {
        return new Promise((resolve, reject) => {
          apiCallQueue.push({ apiFunction, resolve, reject });
          processQueue();
        });
      }

      async function processQueue() {
        if (isProcessingQueue || apiCallQueue.length === 0) return;

        isProcessingQueue = true;

        while (apiCallQueue.length > 0) {
          const { apiFunction, resolve, reject } = apiCallQueue.shift();

          try {
            const result = await apiFunction();
            resolve(result);

            // Wait between API calls to respect rate limits
            const now = Date.now();
            const timeSinceLastCall = now - lastAICall;
            if (timeSinceLastCall < AI_RATE_LIMIT_MS) {
              const waitTime = AI_RATE_LIMIT_MS - timeSinceLastCall;
              await new Promise((r) => setTimeout(r, waitTime));
            }
            lastAICall = Date.now();
          } catch (error) {
            reject(error);
          }
        }

        isProcessingQueue = false;
      }

      const segments = [];
      const recentTranscripts = [];
      const maxTranscriptBuffer = 10;
      let recognition;
      let recognitionInitialized = false;
      let isPaused = false;
      let isCapturing = false;
      let allowAutoRestart = false;
      let aiAnalysisPending = false;
      let aiAnalysisQueue = [];
      let lastAICall = 0;
      const AI_RATE_LIMIT_MS = 2000; // Wait 2 seconds between AI calls

      // For continuous speech without pauses
      let lastTranscriptTime = Date.now();
      let lastFinalTime = Date.now();
      const CONTINUOUS_SPEECH_TIMEOUT = 5000; // 5 seconds before forcing finalization

      // Backend API is now handling the API key securely

      let mind = null; // Mind Elixir instance

      // Get all DOM elements
      const statusIndicator = document.getElementById("status-indicator");
      const statusText = document.getElementById("status-text");
      const startBtn = document.getElementById("start-btn");
      const pauseBtn = document.getElementById("pause-btn");
      const stopBtn = document.getElementById("stop-btn");
      const exportBtn = document.getElementById("export-btn");
      const liveTranscript = document.getElementById("live-transcript");
      const transcriptLog = document.getElementById("transcript-log");
      const noteInput = document.getElementById("note-input");
      const detailsPanel = document.getElementById("details");
      const sourceLangSelect = document.getElementById("source-lang");
      const modelSelect = document.getElementById("model-select");
      const aiOutput = document.getElementById("ai-output");
      const aiStatus = document.getElementById("ai-status");

      function initMindMap() {
        try {
          if (typeof MindElixir === "undefined") {
            console.error("❌ Mind Elixir not loaded - skipping mind map init");
            // Create a placeholder
            const mindmapEl = document.getElementById("mindmap");
            if (mindmapEl) {
              mindmapEl.innerHTML =
                "<p style='padding: 20px; text-align: center;'>Mind map will appear here. Mind Elixir loading...</p>";
            }
            return;
          }

          console.log("🔵 MindElixir found:", typeof MindElixir);

          // Create instance with new
          mind = new MindElixir({
            el: "#mindmap",
            direction: MindElixir.SIDE,
            locale: "en",
            contextMenu: false,
            toolBar: false,
            keypress: false,
            draggable: false,
            editable: false,
          });

          // Create initial data using "Talkstorm" as root
          const initialData = {
            topic: "Talkstorm",
            id: "talkstorm",
            expanded: true,
          };

          // Initialize with data
          mind.init(initialData);

          console.log("✅ Mind map initialized");
        } catch (error) {
          console.error("❌ Error initializing mind map:", error);
        }
      }

      // Convert graph nodes to Mind Elixir format - Hub & Spoke Layout
      function convertToMindElixirFormat(sortedNodes) {
        const n = sortedNodes.length;

        // Root node is always "Talkstorm"
        const rootNode = {
          topic: "Talkstorm",
          id: "talkstorm",
          expanded: true,
        };

        if (n === 0) {
          return rootNode;
        }

        if (n <= 5) {
          // For ≤5 nodes: Simple linear structure - all as direct children of Talkstorm
          rootNode.children = sortedNodes.map((node) => ({
            topic: node.label,
            id: node.id,
            expanded: true,
          }));
          return rootNode;
        }

        // For >5 nodes: Hub & Spoke layout
        // 1) Talkstorm (center/root)
        // 2) Bubble nodes: up to 35% of total, directly connected to Talkstorm
        // 3) Branch nodes: rest, children of bubble nodes

        const bubbleSize = Math.max(1, Math.floor(n * 0.35));
        const bubbleNodes = sortedNodes.slice(0, bubbleSize);
        const branchNodes = sortedNodes.slice(bubbleSize);

        console.log(
          `📊 Talkstorm Layout: ${n} nodes | Bubble: ${bubbleNodes.length} | Branches: ${branchNodes.length}`
        );

        // Build bubble layer (direct children of Talkstorm)
        const bubbleChildren = bubbleNodes.map((bubbleNode) => {
          // Each bubble node gets some branch nodes as children
          const childrenPerBubble = Math.floor(
            branchNodes.length / bubbleNodes.length
          );
          const startIdx = bubbleNodes.indexOf(bubbleNode) * childrenPerBubble;
          const endIdx = startIdx + childrenPerBubble;
          const nodeChildren = branchNodes.slice(startIdx, endIdx);

          return {
            topic: bubbleNode.label,
            id: bubbleNode.id,
            expanded: true,
            children: nodeChildren.map((node) => ({
              topic: node.label,
              id: node.id,
              expanded: true,
            })),
          };
        });

        // Build root with bubble children
        rootNode.children = bubbleChildren;

        return rootNode;
      }

      function populateSelect(select, options, preferred) {
        select.innerHTML = "";
        options.forEach((option) => {
          const opt = document.createElement("option");
          opt.value = option.code;
          opt.textContent = option.label;
          select.appendChild(opt);
        });
        if (preferred && options.some((opt) => opt.code === preferred)) {
          select.value = preferred;
        }
      }

      function tokenize(text) {
        // Simple tokenization for storing segments (AI handles the intelligence)
        return (text.toLowerCase().match(/[a-z0-9'\-]+/g) || []).filter(
          (token) => token.length > 2
        );
      }

      // extractPhrases() removed - AI handles intelligent phrase extraction

      function decayGraph(factor = 0.995) {
        for (const node of graph.nodes.values()) {
          node.weight *= factor;
          if (node.weight < 0.05) {
            graph.nodes.delete(node.id);
          }
        }
        for (const edge of graph.edges.values()) {
          edge.weight *= factor;
          if (edge.weight < 0.05) {
            graph.edges.delete(edge.id);
          }
        }
      }

      function addNode(id, label, increment) {
        if (!graph.nodes.has(id)) {
          graph.nodes.set(id, { id, label, weight: 0 });
        }
        graph.nodes.get(id).weight += increment;
      }

      // Check if a node with similar label already exists
      function findExistingNode(label) {
        const normalizedLabel = label.toLowerCase();
        for (const [nodeId, node] of graph.nodes.entries()) {
          if (node.label.toLowerCase() === normalizedLabel) {
            return node;
          }
        }
        return null;
      }

      function addEdge(a, b, increment) {
        // Validate and normalize increment
        const safeIncrement =
          increment && !isNaN(increment) ? Number(increment) : 1;

        const id = a < b ? `${a}|${b}` : `${b}|${a}`;
        if (!graph.edges.has(id)) {
          graph.edges.set(id, {
            id,
            source: a,
            target: b,
            weight: safeIncrement,
          });
        } else {
          graph.edges.get(id).weight += safeIncrement;
        }
      }

      // Track recent text to prevent duplicate processing (anti-stutter)
      const recentTextHashes = new Map();
      function hashText(text) {
        let hash = 0;
        for (let i = 0; i < text.length; i++) {
          const char = text.charCodeAt(i);
          hash = (hash << 5) - hash + char;
          hash = hash & hash;
        }
        return hash;
      }

      function isDuplicate(text, withinMs = 1000) {
        const hash = hashText(text.toLowerCase());
        const now = Date.now();

        if (recentTextHashes.has(hash)) {
          const seenAt = recentTextHashes.get(hash);
          if (now - seenAt < withinMs) {
            return true;
          }
        }

        recentTextHashes.set(hash, now);

        // Cleanup old hashes
        for (const [h, time] of recentTextHashes.entries()) {
          if (now - time > withinMs * 10) {
            recentTextHashes.delete(h);
          }
        }

        return false;
      }

      async function processTranscript(text, isFinal) {
        if (!text.trim()) return;

        const now = Date.now();

        // Update transcript timestamp
        lastTranscriptTime = now;

        // Track when we last had a final result
        if (isFinal) {
          lastFinalTime = now;
        }

        // Check if continuous speech without pause (force finalization)
        const timeSinceLastFinal = now - lastFinalTime;
        const isForcedFinal =
          !isFinal &&
          timeSinceLastFinal > CONTINUOUS_SPEECH_TIMEOUT &&
          text.length > 30;

        // Combine natural finalization with forced finalization
        const shouldProcessAsFinal = isFinal || isForcedFinal;

        // Skip if this is a duplicate of recent text (within 1 second)
        if (shouldProcessAsFinal && isDuplicate(text, 1000)) {
          return;
        }

        // For final sentences, use AI to extract theme
        if (shouldProcessAsFinal && text.length > 20) {
          if (isForcedFinal) {
            console.log(
              `🔵 Forcing finalization after ${Math.round(
                timeSinceLastFinal / 1000
              )}s of continuous speech`
            );
          }
          await processWithAI(text);
          lastFinalTime = now; // Reset timer after processing
        } else if (text.length > 20) {
          // For interim results, skip AI processing to save API calls
          return;
        }

        if (shouldProcessAsFinal) {
          const timestamp = new Date();
          segments.push({
            id: crypto.randomUUID(),
            text,
            tokens: tokenize(text),
            createdAt: timestamp.toISOString(),
          });
          recentTranscripts.push(text);
          if (recentTranscripts.length > maxTranscriptBuffer) {
            recentTranscripts.shift();
          }
          appendSegment(text, timestamp);

          // Keep bulk analysis for summary display
          await analyzeWithGroq();
        }
      }

      async function processWithAI(sentence) {
        try {
          updateAIStatus("Extracting theme...", false);

          // Step 1: Extract theme from sentence (queued)
          const { theme } = await queueAPICall(async () => {
            const themeResponse = await fetch(
              "http://localhost:3001/api/extract-theme",
              {
                method: "POST",
                headers: { "Content-Type": "application/json" },
                body: JSON.stringify({
                  sentence,
                  model: modelSelect.value,
                }),
              }
            );

            if (!themeResponse.ok) throw new Error("Theme extraction failed");
            const data = await themeResponse.json();
            return data;
          });

          if (!theme) return;

          // Filter out conversational AI responses
          const conversationalPatterns = [
            /i['\u2019]d?\s+(be\s+)?happy/i,
            /i can\s+/i,
            /i would\s+/i,
            /id happy/i,
            /create.*mind.*map.*real/i,
            /^i\s+/i,
            /^i'd\s+/i,
            /^i'am\s+/i,
            /can help/i,
            /would you like/i,
            /let me/i,
          ];

          const isConversational = conversationalPatterns.some((pattern) =>
            pattern.test(theme)
          );

          if (isConversational || theme.length > 50) {
            console.warn(`🚫 Rejected conversational theme: "${theme}"`);
            // Extract first 3 words as fallback
            const words = sentence
              .split(/\s+/)
              .filter((w) => w.length > 2)
              .slice(0, 3);
            theme = words.join(" ") || sentence.substring(0, 30);
            console.log(`✅ Using fallback theme: "${theme}"`);
          }

          // Step 2: Get existing nodes with their current weights
          const allExistingNodes = Array.from(graph.nodes.values());

          // Filter to top N nodes by weight for faster, more relevant connections
          // This focuses on the most important/recent topics
          const MAX_NODES_TO_CONSIDER = 15; // Consider top 15 nodes
          const topExistingNodes = allExistingNodes
            .sort((a, b) => b.weight - a.weight)
            .slice(0, MAX_NODES_TO_CONSIDER);

          const existingNodeLabels = topExistingNodes.map((n) => n.label);

          // Step 3: Find connections to existing nodes (queued)
          updateAIStatus("Finding connections...", false);
          const { connections: connectionsData } = await queueAPICall(
            async () => {
              const connectionsResponse = await fetch(
                "http://localhost:3001/api/find-connections",
                {
                  method: "POST",
                  headers: { "Content-Type": "application/json" },
                  body: JSON.stringify({
                    newNode: theme,
                    existingNodes: existingNodeLabels,
                    model: modelSelect.value,
                  }),
                }
              );

              let connections = [];
              if (connectionsResponse.ok) {
                const data = await connectionsResponse.json();
                connections = data.connections || [];
              }
              return { connections };
            }
          );

          let connections = connectionsData || [];

          // Ensure at least one connection to maintain single graph
          // If no AI connections found, connect to the highest weighted node from ALL nodes
          if (connections.length === 0 && allExistingNodes.length > 0) {
            const highestWeighted = allExistingNodes.sort(
              (a, b) => b.weight - a.weight
            )[0];
            connections.push({
              node: highestWeighted.label,
              strength: 0.3,
              reason: "fallback",
            });
          }

          // Step 4: Reassign weights to existing nodes based on relevance
          // Nodes mentioned in connections get additional weight
          const weightIncrement = 3; // Add weight to connected existing nodes
          const validatedConnections = []; // Store validated connections for reporting

          for (const conn of connections) {
            const nodeId = conn.node.toLowerCase();
            // Validate conn.strength and ensure it's numeric
            const strength = Number(conn.strength);
            const validStrength =
              !isNaN(strength) && strength > 0 ? strength : 0.5;

            if (graph.nodes.has(nodeId)) {
              const node = graph.nodes.get(nodeId);
              node.weight += weightIncrement * validStrength;
              // Cap weight at a reasonable maximum
              node.weight = Math.min(node.weight, 100);

              // Store for reporting
              validatedConnections.push({
                node: conn.node,
                strength: validStrength,
              });
            }
          }

          // Step 5: Check if theme already exists (avoid duplicates)
          // Normalize theme ID to lowercase to prevent duplicates
          const normalizedThemeId = theme.toLowerCase().trim();

          // Check if node exists by ID (normalized)
          let existingNode;
          if (graph.nodes.has(normalizedThemeId)) {
            existingNode = graph.nodes.get(normalizedThemeId);
          } else {
            // Check by label match as fallback
            existingNode = findExistingNode(theme);
          }

          let nodeWeight;
          if (existingNode) {
            // Node already exists, just increase its weight
            existingNode.weight += weightIncrement + 5; // Add bonus for being mentioned
            existingNode.weight = Math.min(existingNode.weight, 100); // Cap
            nodeWeight = existingNode.weight;
          } else {
            // New node, add it with normalized ID but proper label
            const baseWeight = 5;
            const connectionBonus = connections.length * 2;
            nodeWeight = baseWeight + connectionBonus;
            addNode(normalizedThemeId, theme, nodeWeight);
          }

          // Step 6: Add connections to existing nodes using validated connections
          for (const conn of validatedConnections) {
            addEdge(
              normalizedThemeId,
              conn.node.toLowerCase(),
              conn.strength * 10
            );
          }

          // Step 7: Apply decay to nodes not connected to recent themes
          decayGraph(0.995);

          // Step 8: Update mindmap with heap layout
          updateMindmap();

          // Calculate weight changes using validated connections
          const weightChanges = [];
          for (const conn of validatedConnections) {
            weightChanges.push(
              `${conn.node}+${Math.round(weightIncrement * conn.strength)}`
            );
          }

          updateAIStatus(
            `Added: "${theme}" (weight: ${nodeWeight})${
              weightChanges.length > 0
                ? ` | Boosted: ${weightChanges.join(", ")}`
                : ""
            }`,
            true
          );
        } catch (error) {
          console.error("AI processing error:", error);
          if (error.message.includes("429")) {
            updateAIStatus(
              "Rate limited - slowing down...",
              false,
              "Too many requests. Wait a moment."
            );
          } else {
            updateAIStatus("AI processing failed", false, error.message);
          }
        }
      }

      async function analyzeWithGroq() {
        if (aiAnalysisPending) return;

        const transcriptsToAnalyze = recentTranscripts.slice(-3).join(" ");
        if (transcriptsToAnalyze.length < 50) return; // Wait for more content

        aiAnalysisPending = true;
        updateAIStatus("Analyzing...", false);

        try {
          const model = modelSelect.value;

          // Call backend API (queued to serialize with other API calls)
          const data = await queueAPICall(async () => {
            const response = await fetch("http://localhost:3001/api/analyze", {
              method: "POST",
              headers: {
                "Content-Type": "application/json",
              },
              body: JSON.stringify({
                transcripts: transcriptsToAnalyze,
                model: model,
              }),
            });

            // Check response status first
            if (!response.ok) {
              const errorData = await response
                .json()
                .catch(() => ({ error: "Unknown error" }));

              // Handle rate limiting
              if (response.status === 429) {
                updateAIStatus(
                  "Rate limited - slowing down...",
                  false,
                  "Too many requests. Wait a moment."
                );
                throw new Error("Rate limited");
              }

              // Other errors
              throw new Error(
                errorData.message ||
                  errorData.error ||
                  `API error: ${response.status}`
              );
            }

            return await response.json();
          });

          const analysis = data.analysis;

          if (analysis) {
            processAIAnalysis(analysis);
            updateAIStatus("Analysis complete", true);
            displayAISummary(analysis);
          }
        } catch (error) {
          console.error("AI Analysis error:", error);

          // Only show generic errors if not handled above
          if (
            !error.message.includes("429") &&
            !error.message.includes("Rate limited")
          ) {
            updateAIStatus("Analysis failed", false, error.message);
          }
        } finally {
          aiAnalysisPending = false;
        }
      }

      function processAIAnalysis(analysis) {
        // Add concepts as nodes
        if (analysis.concepts) {
          analysis.concepts.forEach((concept) => {
            const normalizedConcept = concept.toLowerCase().trim();
            addNode(normalizedConcept, concept, 5); // Higher weight for AI-extracted concepts
          });
        }

        // Add relationships as edges
        if (analysis.relationships) {
          analysis.relationships.forEach((rel) => {
            const source = rel.source?.toLowerCase().trim();
            const target = rel.target?.toLowerCase().trim();
            // Ensure strength is numeric and valid
            let strength = Number(rel.strength);
            if (isNaN(strength) || strength <= 0) {
              strength = 1;
            }
            strength = Math.min(strength, 10);

            if (source && target && source !== target) {
              addEdge(source, target, strength);
            }
          });
        }

        updateMindmap();
      }

      function displayAISummary(analysis) {
        let summaryHTML = "";

        if (analysis.summary) {
          summaryHTML += `<p><strong>Summary:</strong> ${analysis.summary}</p>`;
        }

        if (analysis.themes && analysis.themes.length > 0) {
          summaryHTML += `<p><strong>Themes:</strong> ${analysis.themes.join(
            ", "
          )}</p>`;
        }

        if (analysis.concepts && analysis.concepts.length > 0) {
          summaryHTML += `<p><strong>Key Concepts:</strong> ${analysis.concepts
            .slice(0, 10)
            .join(", ")}</p>`;
        }

        aiOutput.innerHTML = summaryHTML || "<p>Analysis complete.</p>";
      }

      function updateAIStatus(message, success = false, error = null) {
        aiStatus.innerHTML = "";
        const pill = document.createElement("div");
        pill.className = success
          ? "metric-pill success"
          : error
          ? "metric-pill danger"
          : "metric-pill";
        pill.textContent = message;
        aiStatus.appendChild(pill);

        if (error) {
          const errorText = document.createElement("small");
          errorText.textContent = error;
          errorText.style.color = "#b91c1c";
          aiStatus.appendChild(errorText);
        }
      }

      function appendSegment(text, timestamp) {
        const wrapper = document.createElement("div");
        wrapper.className = "segment";
        const timeEl = document.createElement("time");
        timeEl.textContent = new Intl.DateTimeFormat([], {
          hour: "numeric",
          minute: "2-digit",
          second: "2-digit",
        }).format(new Date(timestamp));
        const textEl = document.createElement("p");
        textEl.textContent = text;
        wrapper.appendChild(timeEl);
        wrapper.appendChild(textEl);
        transcriptLog.prepend(wrapper);
      }

      function updateMindmap() {
        if (!mind) {
          console.warn("⚠️ Mind map not available yet");
          return;
        }
        const maxVisibleNodes = 20; // Show top 20 nodes

        // Get top N nodes by weight (these will be shown)
        const sortedNodes = Array.from(graph.nodes.values()).sort(
          (a, b) => b.weight - a.weight
        );

        // Take top 20 - these will be arranged in mind map
        const visibleNodes = sortedNodes.slice(0, maxVisibleNodes);

        // Convert to Mind Elixir format (heap structure)
        const mindData = convertToMindElixirFormat(visibleNodes);

        // Update the mind map by re-initializing with new data
        mind.init({ nodeData: mindData });
      }

      function showNodeDetails(nodeId) {
        const relatedSegments = segments
          .filter((seg) => seg.tokens.includes(nodeId))
          .slice(-6)
          .reverse();

        detailsPanel.innerHTML = "";
        if (!relatedSegments.length) {
          detailsPanel.innerHTML =
            "<p>No captured quotes linked to this topic yet.</p>";
          return;
        }

        for (const seg of relatedSegments) {
          const item = document.createElement("div");
          item.className = "detail-item";
          const time = document.createElement("time");
          time.textContent = new Intl.DateTimeFormat([], {
            hour: "numeric",
            minute: "2-digit",
            second: "2-digit",
          }).format(new Date(seg.createdAt));
          const text = document.createElement("p");
          text.textContent = seg.text;
          item.appendChild(time);
          item.appendChild(text);
          detailsPanel.appendChild(item);
        }
      }

      function resetSession() {
        graph.nodes.clear();
        graph.edges.clear();
        segments.length = 0;
        recentTranscripts.length = 0;
        transcriptLog.innerHTML = "";
        detailsPanel.innerHTML =
          "<p>Select a node in the mindmap to see the most recent notes and quotes linked to it.</p>";
        liveTranscript.textContent = "Waiting for speech…";
        aiOutput.textContent = "AI insights will appear here...";
        updateAIStatus("Ready", false);
        updateMindmap();

        // Only enable start button if recognition is initialized
        startBtn.disabled = !recognitionInitialized;
        pauseBtn.disabled = true;
        stopBtn.disabled = true;
        exportBtn.disabled = true;
        pauseBtn.textContent = "Pause";
        isCapturing = false;
        isPaused = false;
        allowAutoRestart = false;

        if (!recognitionInitialized) {
          setStatus("Initializing speech recognition...", false);
        } else {
          setStatus("Ready • Click 'Start Listening' to begin", false);
        }
      }

      function exportSession() {
        const payload = {
          exportedAt: new Date().toISOString(),
          segments,
          nodes: Array.from(graph.nodes.values()).map((n) => ({
            id: n.id,
            label: n.label,
            weight: n.weight,
          })),
          edges: Array.from(graph.edges.values()).map((e) => ({
            id: e.id,
            source: e.source,
            target: e.target,
            weight: e.weight,
          })),
          metadata: {
            totalNodes: graph.nodes.size,
            totalEdges: graph.edges.size,
            maxWeight: Math.max(
              ...Array.from(graph.nodes.values()).map((n) => n.weight),
              0
            ),
          },
        };
        const blob = new Blob([JSON.stringify(payload, null, 2)], {
          type: "application/json",
        });
        const url = URL.createObjectURL(blob);
        const a = document.createElement("a");
        a.href = url;
        a.download = `mindmap-${Date.now()}.json`;
        a.click();
        URL.revokeObjectURL(url);
      }

      function loadSession(jsonData) {
        try {
          const data =
            typeof jsonData === "string" ? JSON.parse(jsonData) : jsonData;

          // Clear current state
          graph.nodes.clear();
          graph.edges.clear();

          // Load nodes with their weights
          if (data.nodes && Array.isArray(data.nodes)) {
            data.nodes.forEach((node) => {
              graph.nodes.set(node.id, {
                id: node.id,
                label: node.label,
                weight: node.weight || 0,
              });
            });
          }

          // Load edges with their weights
          if (data.edges && Array.isArray(data.edges)) {
            data.edges.forEach((edge) => {
              graph.edges.set(edge.id, {
                id: edge.id,
                source: edge.source,
                target: edge.target,
                weight: edge.weight || 0,
              });
            });
          }

          updateMindmap();

          updateAIStatus("Graph loaded successfully", true);
        } catch (error) {
          console.error("Load error:", error);
          updateAIStatus("Failed to load graph", false, error.message);
        }
      }

      function setStatus(text, active) {
        statusText.textContent = text;
        statusIndicator.classList.toggle("active", active);
      }

      function setupRecognition() {
        console.log("=== SETUP RECOGNITION START ===");
        console.log("SpeechRecognition available:", !!SpeechRecognition);
        console.log("Window.SpeechRecognition:", window.SpeechRecognition);
        console.log(
          "Window.webkitSpeechRecognition:",
          window.webkitSpeechRecognition
        );

        try {
          if (!SpeechRecognition) {
            console.error(
              "❌ Speech recognition not available in this browser"
            );
            setStatus(
              "Speech recognition unavailable in this browser. Please use Chrome-based browsers.",
              false
            );
            startBtn.disabled = true;
            recognitionInitialized = false;
            console.log(
              "recognitionInitialized set to:",
              recognitionInitialized
            );
            return;
          }

          console.log("Creating SpeechRecognition instance...");
          recognition = new SpeechRecognition();
          console.log("✅ Recognition object created:", !!recognition);

          recognitionInitialized = true;
          console.log(
            "✅ recognitionInitialized set to:",
            recognitionInitialized
          );
          recognition.continuous = true;
          recognition.interimResults = true;
          recognition.lang =
            sourceLangSelect.value === "auto"
              ? navigator.language || "en-US"
              : sourceLangSelect.value;

          recognition.onresult = (event) => {
            let interimTranscript = "";
            for (let i = event.resultIndex; i < event.results.length; ++i) {
              const result = event.results[i];
              const transcript = result[0].transcript.trim();
              if (!transcript) continue;
              if (result.isFinal) {
                liveTranscript.textContent = "✔ " + transcript;
                processTranscript(transcript, true);
              } else {
                interimTranscript = transcript;
                liveTranscript.textContent = "… " + transcript;
                processTranscript(transcript, false);
              }
            }
            if (
              !interimTranscript &&
              !event.results[event.results.length - 1]?.isFinal
            ) {
              liveTranscript.textContent = "Listening…";
            }
          };

          recognition.onerror = (event) => {
            console.error("Speech recognition error", event.error);
            setStatus(`Error: ${event.error}`, false);
            startBtn.disabled = false;
            pauseBtn.disabled = true;
            stopBtn.disabled = false;
            allowAutoRestart = false;
            isCapturing = false;
          };

          recognition.onend = () => {
            if (isCapturing && !isPaused && allowAutoRestart) {
              setStatus("Restarting capture…", true);
              recognition.start();
            }
          };
        } catch (error) {
          console.error("❌ ERROR in setupRecognition:", error);
          console.error("Stack trace:", error.stack);
          recognitionInitialized = false;
          setStatus(
            "Failed to initialize speech recognition: " + error.message,
            false
          );
          startBtn.disabled = true;
        }
        console.log(
          "=== SETUP RECOGNITION END. Initialized:",
          recognitionInitialized,
          "==="
        );
      }

      startBtn.addEventListener("click", () => {
        console.log("🔴 Start button clicked");
        console.log("🔴 Recognition initialized:", recognitionInitialized);
        console.log("🔴 Recognition object exists:", !!recognition);

        if (!recognitionInitialized || !recognition) {
          console.error("🔴 Speech recognition not initialized");
          console.error("🔴 Details:", {
            recognitionInitialized,
            recognition: !!recognition,
            SpeechRecognitionAvailable: !!SpeechRecognition,
          });
          setStatus(
            "Speech recognition not initialized. Check console for details (F12). Browser must be Chrome/Edge.",
            false
          );
          return;
        }
        recognition.lang =
          sourceLangSelect.value === "auto"
            ? navigator.language || "en-US"
            : sourceLangSelect.value;
        allowAutoRestart = true;
        recognition.start();
        isCapturing = true;
        isPaused = false;
        pauseBtn.textContent = "Pause";
        setStatus(
          "Listening… speak naturally for live AI-powered mindmap.",
          true
        );
        startBtn.disabled = true;
        pauseBtn.disabled = false;
        stopBtn.disabled = false;
        exportBtn.disabled = false;
      });

      pauseBtn.addEventListener("click", () => {
        if (!recognition) return;
        if (!isPaused) {
          allowAutoRestart = false;
          recognition.stop();
          isPaused = true;
          pauseBtn.textContent = "Resume";
          setStatus("Paused • resume when ready", false);
        } else {
          recognition.lang =
            sourceLangSelect.value === "auto"
              ? navigator.language || "en-US"
              : sourceLangSelect.value;
          allowAutoRestart = true;
          recognition.start();
          isPaused = false;
          pauseBtn.textContent = "Pause";
          setStatus(
            "Listening… speak naturally for live AI-powered mindmap.",
            true
          );
        }
      });

      stopBtn.addEventListener("click", () => {
        if (recognition) {
          allowAutoRestart = false;
          recognition.stop();
        }
        resetSession();
      });

      exportBtn.addEventListener("click", exportSession);

      const loadBtn = document.getElementById("load-btn");
      const fileInput = document.getElementById("file-input");

      loadBtn.addEventListener("click", () => {
        fileInput.click();
      });

      fileInput.addEventListener("change", (event) => {
        const file = event.target.files[0];
        if (!file) return;

        const reader = new FileReader();
        reader.onload = (e) => {
          loadSession(e.target.result);
        };
        reader.readAsText(file);
      });

      noteInput.addEventListener("keydown", (event) => {
        if ((event.metaKey || event.ctrlKey) && event.key === "Enter") {
          const note = noteInput.value.trim();
          if (note) {
            processTranscript(note, true);
            noteInput.value = "";
          }
        }
      });

      sourceLangSelect.addEventListener("change", () => {
        const lang = sourceLangSelect.value;
        if (recognition) {
          const wasActive = isCapturing && !isPaused;
          if (wasActive) {
            allowAutoRestart = false;
            recognition.stop();
          }
          recognition.lang =
            lang === "auto" ? navigator.language || "en-US" : lang;
          if (wasActive) {
            setTimeout(() => {
              allowAutoRestart = true;
              recognition.start();
            }, 250);
          }
        }
        setStatus(
          `Source language set to ${sourceLangSelect.selectedOptions[0].textContent}.`,
          isCapturing && !isPaused
        );
      });

      function initialiseControls() {
        const preferredSource =
          navigator.language &&
          LANGUAGE_OPTIONS.some((l) => l.code === navigator.language)
            ? navigator.language
            : "en-US";
        populateSelect(sourceLangSelect, LANGUAGE_OPTIONS, preferredSource);
      }

      // ====== CRITICAL DEBUG INFO ======
      console.log("🔵 ====== STARTING INITIALIZATION ======");
      console.log("🔵 SpeechRecognition in window:", window.SpeechRecognition);
      console.log(
        "🔵 webkitSpeechRecognition in window:",
        window.webkitSpeechRecognition
      );
      console.log(
        "🔵 Mind Elixir available:",
        typeof MindElixir !== "undefined"
      );

      // Initialize speech recognition FIRST (critical)
      initialiseControls();
      console.log("🔵 Controls initialized");

      setupRecognition();
      console.log(
        "🔵 Recognition setup complete. Initialized:",
        recognitionInitialized
      );

      // Initialize mind map (can fail without breaking speech)
      if (typeof MindElixir !== "undefined") {
        initMindMap();
        console.log("🔵 Mind map initialized:", mind !== null);
      } else {
        console.warn("⚠️ MindElixir not loaded yet, will retry...");
        // Retry after a delay
        setTimeout(() => {
          if (typeof MindElixir !== "undefined") {
            initMindMap();
            console.log("🔵 Mind map initialized (retry):", mind !== null);
          } else {
            console.error("❌ MindElixir failed to load");
          }
        }, 1000);
      }

      resetSession();
      console.log(
        "🔵 Initialization complete. Speech recognition available:",
        recognitionInitialized,
        "Recognition object:",
        !!recognition
      );
      console.log("🔵 ====== INITIALIZATION COMPLETE ======");
    </script>
  </body>
</html>
